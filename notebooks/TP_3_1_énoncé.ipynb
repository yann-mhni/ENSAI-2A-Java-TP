{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "588fc21f",
      "metadata": {
        "id": "588fc21f"
      },
      "source": [
        "**Avant de débuter ce TP** :\n",
        "\n",
        "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
        "2. **Installez les paquets ci-dessous** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d4bfabb9",
      "metadata": {
        "id": "d4bfabb9",
        "outputId": "04fc6894-e2bc-4b91-de54-0d0420f012d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aeon\n",
            "  Downloading aeon-1.3.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting deprecated>=1.2.13 (from aeon)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numba<0.62.0,>=0.55 in /usr/local/lib/python3.12/dist-packages (from aeon) (0.60.0)\n",
            "Requirement already satisfied: numpy<2.3.0,>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from aeon) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from aeon) (25.0)\n",
            "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from aeon) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.8.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from aeon) (1.6.1)\n",
            "Collecting scipy<1.16.0,>=1.9.0 (from aeon)\n",
            "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from aeon) (4.15.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated>=1.2.13->aeon) (1.17.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba<0.62.0,>=0.55->aeon) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->aeon) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->aeon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->aeon) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.0.0->aeon) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.0.0->aeon) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.4.0,>=2.0.0->aeon) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.10)\n",
            "Downloading aeon-1.3.0-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.5-py3-none-any.whl (828 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchinfo, scipy, lightning-utilities, deprecated, aeon, torchmetrics, pytorch-lightning, lightning\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.2\n",
            "    Uninstalling scipy-1.16.2:\n",
            "      Successfully uninstalled scipy-1.16.2\n",
            "Successfully installed aeon-1.3.0 deprecated-1.2.18 lightning-2.5.5 lightning-utilities-0.15.2 pytorch-lightning-2.5.5 scipy-1.15.3 torchinfo-1.8.0 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "! pip install aeon lightning torchmetrics torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d69fead1",
      "metadata": {
        "id": "d69fead1"
      },
      "source": [
        "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "21a42c0e",
      "metadata": {
        "id": "21a42c0e"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
        "logger = logging.getLogger(\"lightning\")\n",
        "logger.propagate = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a64f9ac0",
      "metadata": {
        "id": "a64f9ac0"
      },
      "source": [
        "# Prédiction de la concentration en benzène\n",
        "\n",
        "Dans ce notebook, vous allez travailler sur le jeu de données [Benzene Concentration](https://zenodo.org/records/3902673).\n",
        "Voici quelques informations supplémentaires sur le jeu de données :\n",
        "\n",
        "> L'objectif de ce jeu de données est de prédire la concentration de benzène dans une ville italienne. Ce jeu de données contient 8 878 séries temporelles obtenues à partir de l'ensemble de données sur la qualité de l'air provenant du référentiel UCI. La série temporelle comporte 8 dimensions qui consistent en des réponses moyennes horaires provenant d'un ensemble de 5 capteurs chimiques à oxyde métallique intégrés dans un dispositif multicapteur chimique de qualité de l'air, ainsi que la température, l'humidité relative et l'humidité absolue. Le dispositif multicapteur chimique de qualité de l'air était situé sur le terrain dans une zone fortement polluée, au niveau de la route, dans une ville italienne. Les données ont été enregistrées de mars 2004 à février 2005 (un an), ce qui représente les enregistrements librement accessibles les plus longs des réponses des capteurs chimiques de qualité de l'air déployés sur le terrain. Les concentrations moyennes horaires de référence pour le CO, les hydrocarbures non méthaniques, le benzène, les oxydes d'azote totaux (NOx) et le dioxyde d'azote (NO2) ont été fournies par un analyseur certifié de référence situé au même endroit.\n",
        "\n",
        "Le benzène est un composé organique appartenant à la famille des hydrocarbures aromatiques monocycliques.\n",
        "Il est dangereux à de nombreux titres [...] : très inflammable, toxique, irritant, cancérogène et mutagène.\n",
        "Les principales voies d'exposition de la population au benzène sont les vapeurs d'essence, les gaz d'échappement, les émanations industrielles, la fumée de cigarette ainsi que la combustion du bois (source : [Wikipedia](https://fr.wikipedia.org/wiki/Benzène)).\n",
        "\n",
        "**L'objectif est de prédire la concentration en benzène à partir des séries temporelles.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b51a67",
      "metadata": {
        "id": "b7b51a67"
      },
      "source": [
        "## Téléchargement et visualisation des données\n",
        "\n",
        "La fonction `load_dataset()` définie ci-dessous permet de télécharger le jeu de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cda6ad0e",
      "metadata": {
        "id": "cda6ad0e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def load_dataset(train, path=\"data\"):\n",
        "    \"\"\"Charge le jeu de données.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train : bool\n",
        "        Si True, renvoie le jeu d'entraînement. Sinon, renvoie le jeu de validation.\n",
        "\n",
        "    path : str\n",
        "        Chemin du répertoire où charger ou télécharger le jeu de données.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : Tensor, shape = (n_observations, n_canaux, n_points)\n",
        "        Entrées.\n",
        "\n",
        "    y : Tensor, shape = (n_observations,)\n",
        "        Sorties (labels).\n",
        "    \"\"\"\n",
        "    from aeon.datasets import load_regression\n",
        "\n",
        "    # Determine which split is (down)loaded\n",
        "    split = \"train\" if train else \"test\"\n",
        "\n",
        "    # (Down)load the dataset\n",
        "    X, y = load_regression(\"BenzeneConcentration\", split=split, extract_path=path)\n",
        "\n",
        "    # Format y\n",
        "    y = y.reshape(-1, 1)\n",
        "\n",
        "    # Convert the arrays to tensors\n",
        "    X = torch.from_numpy(X).to(dtype=torch.float32)\n",
        "    y = torch.from_numpy(y).to(dtype=torch.float32)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cd80c34",
      "metadata": {
        "id": "2cd80c34"
      },
      "source": [
        "Il suffit d'appeler cette fonction pour récupérer les jeux d'entraînement et de validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a3e821a",
      "metadata": {
        "id": "0a3e821a"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = load_dataset(train=True)\n",
        "X_val, y_val = load_dataset(train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c02b8348",
      "metadata": {
        "id": "c02b8348"
      },
      "source": [
        "Pour chaque jeu de données, nous avons 2 variables Python :\n",
        "\n",
        "* `X` contient les entrées (c'est-à-dire les séries temporelles) ; il s'agit d'un tenseur de taille `(n_observations, n_canaux, n_points)`.\n",
        "* `y` contient les sorties (c'est-à-dire les concentrations en benzène) ; il s'agit d'un tenseur de taille `(n_observations,)`.\n",
        "\n",
        "\n",
        "### Question 1\n",
        "\n",
        "Déterminez le nombre d'enregistrements dans les jeux d'entraînement et de validation.\n",
        "Déterminez (par du code) la taille de chaque observation (on admettra que toutes les observations ont la même taille, il suffit donc de calculer la taille d'une seule observation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceab934d",
      "metadata": {
        "id": "ceab934d"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebbe6e0f",
      "metadata": {
        "id": "ebbe6e0f"
      },
      "source": [
        "La fonction `plot_sample()` définie ci-dessous permet d'afficher une observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f176cc",
      "metadata": {
        "id": "01f176cc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_sample(X, y, idx):\n",
        "    \"\"\"Affiche une observation d'un jeu de données.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape = (n_observations, n_canaux, n_points)\n",
        "        Entrées.\n",
        "\n",
        "    y : array, shape = (n_observations,)\n",
        "        Sorties (labels).\n",
        "\n",
        "    idx : int\n",
        "        Indice de l'observation à afficher.\n",
        "    \"\"\"\n",
        "    if not (isinstance(idx, int) and (0 <= idx < len(X))):\n",
        "        raise ValueError(\"L'indice n'est pas valide.\")\n",
        "\n",
        "    plt.figure(figsize=(12, 3))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    labels = [\n",
        "        \"Monoxyde de carbone\",\n",
        "        \"Hydrocarbures non méthaniques\",\n",
        "        \"Oxydes d'azote\",\n",
        "        \"Dioxyde d'azote\",\n",
        "        \"Ozone\",\n",
        "    ]\n",
        "    for label, i in zip(labels, range(5)):\n",
        "        plt.plot(X[idx, i], color=f\"C{i}\", label=label)\n",
        "    plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15))\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    labels = [\"Température\", \"Humidité relative\"]\n",
        "    for label, i in zip(labels, range(5, 7)):\n",
        "        plt.plot(X[idx, i], color=f\"C{i}\", label=label)\n",
        "    plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15))\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    label = \"Humidité absolue\"\n",
        "    i = 7\n",
        "    plt.plot(X[idx, i], color=f\"C{i}\", label=label)\n",
        "    plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.15))\n",
        "\n",
        "    _ = plt.suptitle(f\"Concentration en benzène = {y[idx].item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a20bd6b",
      "metadata": {
        "id": "0a20bd6b"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Appelez la fonction `plot_sample()` pour visualiser quelques observations des jeux d'entraînement et de validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830fff12",
      "metadata": {
        "id": "830fff12"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a8295b7",
      "metadata": {
        "id": "7a8295b7"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Affichez la distribution des concentrations en benzène sur les jeux d'entraînement et de validation. Vous pouvez utiliser la fonction [`matplotlib.pyplot.hist()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1633596f",
      "metadata": {
        "id": "1633596f"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630603a3",
      "metadata": {
        "id": "630603a3"
      },
      "source": [
        "Nous allons évaluer la performance des modèles avec la racine de l’erreur quadratique moyenne (*root mean squared error*) :\n",
        "$$\n",
        "  \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\left( y_i - \\hat{y}_i \\right)^2}\n",
        "$$\n",
        "\n",
        "Un modèle trivial consiste à prédire une constante, quelle que soit les données en entrée.\n",
        "Pour la racine de l’erreur quadratique moyenne, la meilleure constante possible est la moyenne :\n",
        "$$\n",
        "    \\forall j \\in \\{1, \\ldots, n\\}, \\; \\hat{y}_j = \\frac{1}{n} \\sum_{i=1}^n y_i\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8e76106",
      "metadata": {
        "id": "e8e76106"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Calculez les racines des erreurs quadratiques moyennes sur les jeux d'entraînement et de validation. Cela vous fournira une valeur de référence pour évaluer les futurs modèles entraînés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9f4d6de",
      "metadata": {
        "id": "f9f4d6de"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b129f941",
      "metadata": {
        "id": "b129f941"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Créez les *dataloaders* pour les jeux d'entraînement et de validation en utilisant la classe [`torch.utils.data.DataLoader()`](https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) avec des lots de taille $16$. N'oubliez pas de mélanger (suffle) les observations pour le jeu d'entraînement, mais pas pour le jeu de validation. Pour créer les jeux de données, utiliser la classe [`torch.utils.data.TensorDataset()`](https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4e1d59",
      "metadata": {
        "id": "8a4e1d59"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b939e69",
      "metadata": {
        "id": "9b939e69"
      },
      "source": [
        "## Classe de base pour la régression\n",
        "\n",
        "Vous allez entraîner plusieurs modèles avec des architectures différentes.\n",
        "Néanmoins, plusieurs opérations seront identiques pour tous ces modèles.\n",
        "C'est pourquoi nous allons tout d'abord définir une classe de base avec toutes les opérations identiques.\n",
        "La classe `BaseClass()` définie ci-dessous va contenir ces opérations communes.\n",
        "\n",
        "### Question 6\n",
        "\n",
        "Complétez le code manquant dans les méthodes `__init__()`, `step()` et `configure_optimizers()` de la classe `BaseClass()` avec les informations suivantes :\n",
        "* `__init__()` : il faut définir la fonction de perte (`self.loss`) et les métriques pour les jeux d'entraînement (`self.metric_train`) et d'évaluation (`self.metric_val`) ; on utilisera l'erreur quadratique moyenne comme fonction de perte et la racine de l'erreur quadratique moyenne comme métrique d'évaluation.\n",
        "* `step()` : étant donné un lot d'observations (`batch`), il faut :\n",
        "    + récupérer les entrées (`X`) et les sorties (`y`),\n",
        "    + calculer la valeur prédite pour chacune des entrées du lot (`y_pred`),\n",
        "    + calculer la fonction de coût entre les valeurs prédites et les vraies valeurs (`loss`).\n",
        "* `configure_optimizers()` : on utilisera l'algorithme d'optimisation *Adam* avec un taux d'apprentissage de $10^{-4}$.\n",
        "\n",
        "Voici les liens vers les documentations des classes pertinentes :\n",
        "[`torch.nn.MSELoss()`](https://docs.pytorch.org/docs/stable/generated/torch.nn.MSELoss.html),\n",
        "[`torchmetrics.MeanSquaredError()`](https://lightning.ai/docs/torchmetrics/stable/regression/mean_squared_error.html) et\n",
        "[`torch.optim.Adam()`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98316db4",
      "metadata": {
        "id": "98316db4"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "from torchmetrics import MeanSquaredError\n",
        "\n",
        "\n",
        "class BaseClass(L.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructeur.\n",
        "\n",
        "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
        "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "        # Initialisation de la fonction de perte\n",
        "        # self.loss =\n",
        "\n",
        "        # Initialisation des métriques\n",
        "        # self.metric_train =\n",
        "        # self.metric_val =\n",
        "        #### END TODO ####\n",
        "\n",
        "    def step(self, batch, dataset):\n",
        "        \"\"\"Effectue une étape.\n",
        "\n",
        "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
        "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : tuple\n",
        "            Un lot d'observations. Le premier élément du tuple est le lot\n",
        "            des entrées, le second est le lot des labels.\n",
        "\n",
        "        dataset : {\"training\", \"validation\"}\n",
        "            Jeu de données utilisé.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : Tensor, shape = (1,)\n",
        "            La fonction de coût pour ce lot d'observations.\n",
        "        \"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        # X, y =\n",
        "        # y_pred =\n",
        "        # loss =\n",
        "        #### END TODO ###\n",
        "\n",
        "        if dataset == \"training\":\n",
        "            metric = self.metric_train\n",
        "            name = \"train\"\n",
        "            bar_step = True\n",
        "        else:\n",
        "            metric = self.metric_val\n",
        "            name = \"val\"\n",
        "            bar_step = False\n",
        "\n",
        "        metric_score = metric(y_pred, y) # Évaluation de la métrique\n",
        "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "        self.log(f\"metric_{name}\", metric_score, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
        "        return self.step(batch, \"training\")\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        \"\"\"Effectue une étape de validation.\"\"\"\n",
        "        return self.step(batch, \"validation\")\n",
        "\n",
        "    def on_train_start(self):\n",
        "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
        "        string = f\"Version {self.trainer.logger.version}\"\n",
        "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
        "        metrics = self.trainer.callback_metrics\n",
        "        string = (f\"\"\"\n",
        "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
        "            -------------------------------------------------\n",
        "            |     Jeu      | Fonction de perte |    RMSE    |\n",
        "            | ------------ | ----------------- | ---------- |\n",
        "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['metric_train'].item():^12.4f}|\n",
        "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['metric_val'].item():^12.4f}|\n",
        "            -------------------------------------------------\n",
        "        \"\"\")\n",
        "        string = '\\n'.join([line.strip() for line in string.strip().split('\\n')])\n",
        "        print(string, '\\n')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
        "        ### BEGIN TODO ###\n",
        "        # optimizer =\n",
        "        #### END TODO ####\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94bccc6c",
      "metadata": {
        "id": "94bccc6c"
      },
      "source": [
        "## Régression par perceptron multicouche\n",
        "\n",
        "Comme la longueur de chacun des signaux est fixe après prétraitement des données, il est possible d'utiliser un perceptron multicouche.\n",
        "\n",
        "Vous allez implémenter un perceptron multicouche dans la classe `MLP()` définie ci-dessous avec l'architecture séquentielle suivante :\n",
        "\n",
        "* Aplatissement de l'observation pour la transformer en un tenseur à une dimension (un vecteur)\n",
        "* Couche linéaire avec 256 variables en sortie\n",
        "* Fonction d'action ReLU\n",
        "* Couche de désaction (*dropout*) avec une probabilité de $0.2$\n",
        "* Couche linéaire avec 64 variables en sortie\n",
        "* Fonction d'action ReLU\n",
        "* Couche linéaire avec 1 variable en sortie\n",
        "\n",
        "Voici les liens vers les documentations des classes pertinentes :\n",
        "[`torch.nn.Flatten()`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html),\n",
        "[`torch.nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html),\n",
        "[`torch.nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) et\n",
        "[`torch.nn.Dropout()`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html).\n",
        "\n",
        "### Question 7\n",
        "\n",
        "Complétez le code manquant dans les méthodes `__init__()` et `forward()` de la classe `MLP()`.\n",
        "Affichez un résumé de l'architecture. Combien de paramètres entraînables a-t-elle ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79ee19f",
      "metadata": {
        "id": "f79ee19f"
      },
      "outputs": [],
      "source": [
        "class MLP(BaseClass):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### BEGIN TODO ###\n",
        "        # y_pred =\n",
        "        #### END TODO ####\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f5d908",
      "metadata": {
        "id": "d7f5d908"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f410bd2c",
      "metadata": {
        "id": "f410bd2c"
      },
      "source": [
        "### Question 8\n",
        "\n",
        "Entraînez votre modèle pendant $10$ époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b99be49",
      "metadata": {
        "id": "5b99be49"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00838f3",
      "metadata": {
        "id": "c00838f3"
      },
      "source": [
        "## Régression par réseau de neurones convolutif\n",
        "\n",
        "Comme la longueur de chacun des signaux est fixe après prétraitement des données et que les données sont séquentielles, il est également possible et pertinent d'utiliser un réseau de neurones convolutif.\n",
        "\n",
        "Vous allez implémenter un réseau de neurones convolutif dans la classe `CNN()` définie ci-dessous avec l'architecture séquentielle suivante :\n",
        "\n",
        "* Couche de convolution unidimensionnelle avec $16$ canaux en sortie, un noyau de taille $7$ et du rembourrage de telle sorte que la sortie ait la même taille que l'entrée\n",
        "* Fonction d'action ReLU\n",
        "* Couche de regroupement unidimensionnelle avec un noyau et un pas de taille $2$\n",
        "* Couche de convolution unidimensionnelle avec $32$ canaux en sortie, un noyau de taille $5$ et du rembourrage de telle sorte que la sortie ait la même taille que l'entrée\n",
        "* Fonction d'action ReLU\n",
        "* Couche de regroupement unidimensionnelle avec un noyau et un pas de taille $2$\n",
        "* Couche de convolution unidimensionnelle avec $64$ canaux en sortie, un noyau de taille $3$ et du rembourrage de telle sorte que la sortie ait la même taille que l'entrée\n",
        "* Fonction d'action ReLU\n",
        "* Couche de regroupement unidimensionnelle avec un noyau et un pas de taille $2$\n",
        "* Aplatissement de l'entrée (en deux dimensions) pour la transformer en un tenseur à une dimension (un vecteur)\n",
        "* Couche linéaire avec $1920$ variables en entrée et $256$ variables en sortie\n",
        "* Fonction d'action ReLU\n",
        "* Couche linéaire avec $1$ variable en sortie\n",
        "\n",
        "Voici les liens vers les documentations des classes pertinentes :\n",
        "[`torch.nn.Conv1d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html),\n",
        "[`torch.nn.ReLU()`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html),\n",
        "[`torch.nn.MaxPool1d()`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html),\n",
        "[`torch.nn.Flatten()`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) et\n",
        "[`torch.nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
        "\n",
        "### Question 9\n",
        "\n",
        "Complétez le code manquant dans les méthodes `__init__()` et `forward()` de la classe `CNN()`.\n",
        "Affichez un résumé de l'architecture. Combien de paramètres entraînables a-t-elle ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dce17bc",
      "metadata": {
        "id": "7dce17bc"
      },
      "outputs": [],
      "source": [
        "class CNN(BaseClass):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### BEGIN TODO ###\n",
        "        # y_pred =\n",
        "        #### END TODO ####\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25db62f0",
      "metadata": {
        "scrolled": false,
        "id": "25db62f0"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "679a9aa9",
      "metadata": {
        "id": "679a9aa9"
      },
      "source": [
        "### Question 10\n",
        "\n",
        "Entraînez votre modèle pendant $10$ époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1f52abc",
      "metadata": {
        "id": "d1f52abc"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad25d0c7",
      "metadata": {
        "id": "ad25d0c7"
      },
      "source": [
        "## Régression par réseau de neurones récurrent\n",
        "\n",
        "Comme les données sont séquentielles, il est également possible et pertinent d'utiliser un réseau de neurones récurrent.\n",
        "\n",
        "Vous allez implémenter un réseau de neurones récurrent dans la classe `RNN()` définie ci-dessous avec l'architecture séquentielle suivante :\n",
        "\n",
        "* Couche récurrente de type LSTM (unidirectionnelle) avec $256$ variables pour chaque état caché\n",
        "* Couche linéaire avec 1 variable en sortie\n",
        "\n",
        "Voici les liens vers les documentations des classes pertinentes :\n",
        "[`torch.nn.LSTM()`](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) et\n",
        "[`torch.nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
        "\n",
        "### Question 11\n",
        "\n",
        "Complétez le code manquant dans les méthodes `__init__()` et `forward()` de la classe `RNN()`.\n",
        "Affichez un résumé de l'architecture. Combien de paramètres entraînables a-t-elle ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eaea523",
      "metadata": {
        "id": "0eaea523"
      },
      "outputs": [],
      "source": [
        "class RNN(BaseClass):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        ### BEGIN TODO ###\n",
        "\n",
        "        #### END TODO ####\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### BEGIN TODO ###\n",
        "        # y_pred =\n",
        "        #### END TODO ####\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7d607f",
      "metadata": {
        "id": "fd7d607f"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "014d2f3a",
      "metadata": {
        "id": "014d2f3a"
      },
      "source": [
        "### Question 12\n",
        "\n",
        "Entraînez votre modèle pendant $10$ époques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fa4861",
      "metadata": {
        "id": "92fa4861"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec62a18",
      "metadata": {
        "id": "cec62a18"
      },
      "source": [
        "### Question 13\n",
        "\n",
        "Finalement, lequel de vos trois modèles est le meilleur ? Faîtes-vous mieux que le modèle trivial ? Justifiez votre réponse."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}